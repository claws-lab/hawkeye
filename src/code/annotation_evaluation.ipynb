{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This notebook is used to create the excel sheet for annotators to annotate the tweets as accurate/inaccurate and to evaluate the annotations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import numpy as np\n",
    "import random\n",
    "# import tweepy\n",
    "import datetime\n",
    "from sklearn.metrics import roc_curve,auc\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We read the data and perform the hawkeye algorithm on the data (we process the tweets using the hawkeye) algorithm. This allows us to get the accuracy metric valeus for all the tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes = pd.read_csv(\"../data/notes-00000-13-04-21.tsv\", sep='\\t')\n",
    "ratings = pd.read_csv(\"../data/ratings-00000-13-04-21.tsv\", sep='\\t')\n",
    "notes = notes[['noteId', 'participantId','tweetId','classification']]\n",
    "ratings = ratings[['noteId', 'participantId','helpful']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_lambda = 0.1\n",
    "lambda1 = init_lambda\n",
    "lambda2 = init_lambda\n",
    "lambda3 = init_lambda\n",
    "alpha1 = 1\n",
    "beta1 = 1\n",
    "gamma1 = 1\n",
    "delta1 = 1\n",
    "\n",
    "#initialize goodness (assume every note has highest goodness)\n",
    "init_goodness = 1\n",
    "convergence_threshold = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do initializations\n",
    "ratings['goodness'] = [init_goodness]*len(ratings)\n",
    "ratings['rating'] = ratings.apply(lambda x : 1 if x['helpful']==1 else -1,axis=1)\n",
    "notes['goodness'] = [init_goodness]*len(notes)\n",
    "notes['verdict'] = notes.apply(lambda x : 1 if x['classification']=='NOT_MISLEADING' else -1,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_rating_participants = len(set(ratings['participantId']))\n",
    "no_of_writing_participants = len(set(notes['participantId']))\n",
    "no_of_tweets = len(set(notes['tweetId']))\n",
    "no_of_notes = len(set(notes['noteId']))\n",
    "mu_r = 1*no_of_rating_participants/no_of_rating_participants\n",
    "mu_w = 1*no_of_writing_participants/no_of_writing_participants\n",
    "mu_t = 1*no_of_tweets/no_of_tweets                                       \n",
    "mu_g = 1*no_of_notes/no_of_notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at the beginning :  22:30:35\n",
      "at the end :  22:31:08\n"
     ]
    }
   ],
   "source": [
    "print(\"at the beginning : \",datetime.datetime.now().strftime(\"%H:%M:%S\"))\n",
    "\n",
    "#Fairness of user in rating notes\n",
    "ratings['score_goodness_difference_metric'] = 1-((ratings['rating']-ratings['goodness']).abs()/2)\n",
    "ratings['rating_fairness'] = (ratings.groupby(['participantId'])['score_goodness_difference_metric'].transform(\"sum\") + alpha1*mu_r)/(ratings.groupby(['participantId'])['participantId'].transform(\"count\") + alpha1)\n",
    "\n",
    "#Fairness of user in writing notes\n",
    "notes['writing_fairness'] = (notes.groupby(['participantId'])['goodness'].transform(\"sum\") + beta1*mu_w)/(notes.groupby(['participantId'])['participantId'].transform(\"count\") + beta1)\n",
    "\n",
    "#Accuracy of Tweet\n",
    "notes['weighted_goodness'] = notes['goodness']*notes['verdict']\n",
    "notes['tweet_accuracy'] = (notes.groupby(['tweetId'])['weighted_goodness'].transform(\"sum\") + delta1*mu_t)/(notes.groupby(['tweetId'])['tweetId'].transform(\"count\") + delta1)\n",
    "\n",
    "#Goodness of notes\n",
    "ratings['weighted_rating_fairness'] = ratings['rating_fairness']*ratings['rating']\n",
    "ratings['goodness_term1'] = (ratings.groupby(['noteId'])['weighted_rating_fairness'].transform(\"sum\") + gamma1*mu_g)/(ratings.groupby(['noteId'])['noteId'].transform(\"count\") + gamma1)\n",
    "notes['goodness_term1'] = lambda1*notes.apply(lambda x: 1 if len(ratings.loc[ratings['noteId'] == x['noteId']])==0 else ratings.loc[ratings['noteId'] == x['noteId']].iloc[0]['goodness_term1'],axis=1)\n",
    "notes['goodness_term3'] = lambda3*(1-(notes['tweet_accuracy']-notes['verdict']).abs())\n",
    "notes['goodness'] = 1/3 * (notes['goodness_term1'] + lambda2*notes['writing_fairness'] + notes['goodness_term3'])\n",
    "\n",
    "#IMPORTANT : Update goodness ratings df\n",
    "ratings['goodness'] = ratings.apply(lambda x: notes.loc[notes['noteId'] == x['noteId']].iloc[0]['goodness'],axis=1)\n",
    "\n",
    "print(\"at the end : \",datetime.datetime.now().strftime(\"%H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at the beginning :  22:31:13\n",
      "1  :  4942.80289433259\n",
      "2  :  237.4269628442238\n",
      "3  :  11.77233938098382\n",
      "4  :  0.5936264540711889\n",
      "5  :  0.031199678504140405\n",
      "6  :  0.0017139285413503291\n",
      "7  :  9.447260146477898e-05\n",
      "at the end :  22:35:17\n"
     ]
    }
   ],
   "source": [
    "times = []\n",
    "errors = []\n",
    "t = 1\n",
    "error = math.inf\n",
    "\n",
    "print(\"at the beginning : \",datetime.datetime.now().strftime(\"%H:%M:%S\"))\n",
    "while(error>convergence_threshold):\n",
    "   \n",
    "    old_rating_fairness_values = np.array(ratings['rating_fairness'])\n",
    "    old_writing_fairness_values = np.array(notes['writing_fairness'])\n",
    "    old_tweet_accuracy_values = np.array(notes['tweet_accuracy'])\n",
    "    old_goodness_values = np.array(notes['goodness'])\n",
    "\n",
    "    #Fairness of user in rating notes\n",
    "    ratings['score_goodness_difference_metric'] = 1-((ratings['rating']-ratings['goodness']).abs()/2)\n",
    "    ratings['rating_fairness'] = (ratings.groupby(['participantId'])['score_goodness_difference_metric'].transform(\"sum\") + alpha1*mu_r)/(ratings.groupby(['participantId'])['participantId'].transform(\"count\") + alpha1)\n",
    "    \n",
    "    #Fairness of user in writing notes\n",
    "    notes['writing_fairness'] = (notes.groupby(['participantId'])['goodness'].transform(\"sum\") + beta1*mu_w)/(notes.groupby(['participantId'])['participantId'].transform(\"count\") + beta1)\n",
    "    \n",
    "    #Accuracy of Tweet\n",
    "    notes['weighted_goodness'] = notes['goodness']*notes['verdict']\n",
    "    notes['tweet_accuracy'] = (notes.groupby(['tweetId'])['weighted_goodness'].transform(\"sum\") + delta1*mu_t)/(notes.groupby(['tweetId'])['tweetId'].transform(\"count\") + delta1)\n",
    "    \n",
    "    #Goodness of notes\n",
    "    ratings['weighted_rating_fairness'] = ratings['rating_fairness']*ratings['rating']\n",
    "    ratings['goodness_term1'] = (ratings.groupby(['noteId'])['weighted_rating_fairness'].transform(\"sum\") + gamma1*mu_g)/(ratings.groupby(['noteId'])['noteId'].transform(\"count\") + gamma1)\n",
    "    notes['goodness_term1'] = lambda1*notes.apply(lambda x: 1 if len(ratings.loc[ratings['noteId'] == x['noteId']])==0 else ratings.loc[ratings['noteId'] == x['noteId']].iloc[0]['goodness_term1'],axis=1)\n",
    "    notes['goodness_term3'] = lambda3*(1-(notes['tweet_accuracy']-notes['verdict']).abs())\n",
    "    notes['goodness'] = 1/3 * (notes['goodness_term1'] + lambda2*notes['writing_fairness'] + notes['goodness_term3'])\n",
    "    \n",
    "    #IMPORTANT : Update goodness ratings df\n",
    "    ratings['goodness'] = ratings.apply(lambda x: notes.loc[notes['noteId'] == x['noteId']].iloc[0]['goodness'],axis=1)\n",
    "\n",
    "    new_rating_fairness_values = np.array(ratings['rating_fairness'])\n",
    "    new_writing_fairness_values = np.array(notes['writing_fairness'])\n",
    "    new_tweet_accuracy_values = np.array(notes['tweet_accuracy'])\n",
    "    new_goodness_values = np.array(notes['goodness'])\n",
    "\n",
    "    rating_fairness_error = np.sum(np.absolute((np.subtract(old_rating_fairness_values,new_rating_fairness_values))))\n",
    "    writing_fairness_error = np.sum(np.absolute(np.subtract(old_writing_fairness_values,new_writing_fairness_values)))\n",
    "    tweet_accuracy_error = np.sum(np.absolute(np.subtract(old_tweet_accuracy_values,new_tweet_accuracy_values)))\n",
    "    goodness_error = np.sum(np.absolute(np.subtract(old_goodness_values,new_goodness_values)))\n",
    "\n",
    "    error = max(rating_fairness_error,writing_fairness_error,tweet_accuracy_error,goodness_error)\n",
    "    print(t,\" : \",error)\n",
    "    times.append(t)\n",
    "    errors.append(error)\n",
    "    t += 1\n",
    "    \n",
    "print(\"at the end : \",datetime.datetime.now().strftime(\"%H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>noteId</th>\n",
       "      <th>participantId</th>\n",
       "      <th>tweetId</th>\n",
       "      <th>classification</th>\n",
       "      <th>goodness</th>\n",
       "      <th>verdict</th>\n",
       "      <th>writing_fairness</th>\n",
       "      <th>weighted_goodness</th>\n",
       "      <th>tweet_accuracy</th>\n",
       "      <th>goodness_term1</th>\n",
       "      <th>goodness_term3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>1354875505246351360</td>\n",
       "      <td>7DCE02372757684773156C51BD8A856B</td>\n",
       "      <td>1354848253729234944</td>\n",
       "      <td>MISINFORMED_OR_POTENTIALLY_MISLEADING</td>\n",
       "      <td>0.005638</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.204779</td>\n",
       "      <td>-0.005638</td>\n",
       "      <td>0.005741</td>\n",
       "      <td>-0.002989</td>\n",
       "      <td>-0.000574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4657</th>\n",
       "      <td>1354862350009069568</td>\n",
       "      <td>52E7E8AC27398A29A5D8B54CD24439F9</td>\n",
       "      <td>1354848253729234944</td>\n",
       "      <td>MISINFORMED_OR_POTENTIALLY_MISLEADING</td>\n",
       "      <td>0.015433</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.275441</td>\n",
       "      <td>-0.015433</td>\n",
       "      <td>0.005741</td>\n",
       "      <td>0.019330</td>\n",
       "      <td>-0.000574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1609</th>\n",
       "      <td>1354893429977849861</td>\n",
       "      <td>8F404408FB172B6104E0D8003C9B129C</td>\n",
       "      <td>1354848253729234944</td>\n",
       "      <td>MISINFORMED_OR_POTENTIALLY_MISLEADING</td>\n",
       "      <td>0.021244</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.353497</td>\n",
       "      <td>-0.021244</td>\n",
       "      <td>0.005741</td>\n",
       "      <td>0.028956</td>\n",
       "      <td>-0.000574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4870</th>\n",
       "      <td>1354855483631423493</td>\n",
       "      <td>0CC2FBF56892C9911DFAFBA2C4FF2E4C</td>\n",
       "      <td>1354848253729234944</td>\n",
       "      <td>MISINFORMED_OR_POTENTIALLY_MISLEADING</td>\n",
       "      <td>0.008414</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.047435</td>\n",
       "      <td>-0.008414</td>\n",
       "      <td>0.005741</td>\n",
       "      <td>0.021074</td>\n",
       "      <td>-0.000574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1431</th>\n",
       "      <td>1357798998405447682</td>\n",
       "      <td>02C657744DA50BCE2A90C2D4AB0CDC6E</td>\n",
       "      <td>1354848253729234944</td>\n",
       "      <td>MISINFORMED_OR_POTENTIALLY_MISLEADING</td>\n",
       "      <td>0.017171</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.143030</td>\n",
       "      <td>-0.017171</td>\n",
       "      <td>0.005741</td>\n",
       "      <td>0.037783</td>\n",
       "      <td>-0.000574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>1354875060885090309</td>\n",
       "      <td>DD591AE4F8045D93FFE2C45C394AC8DE</td>\n",
       "      <td>1354848253729234944</td>\n",
       "      <td>MISINFORMED_OR_POTENTIALLY_MISLEADING</td>\n",
       "      <td>0.015138</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.205696</td>\n",
       "      <td>-0.015138</td>\n",
       "      <td>0.005741</td>\n",
       "      <td>0.025419</td>\n",
       "      <td>-0.000574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1590</th>\n",
       "      <td>1354868783840595969</td>\n",
       "      <td>9EE481CF8EDD9F2F08B20C7ED2C3355D</td>\n",
       "      <td>1354848253729234944</td>\n",
       "      <td>MISINFORMED_OR_POTENTIALLY_MISLEADING</td>\n",
       "      <td>0.016435</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.211177</td>\n",
       "      <td>-0.016435</td>\n",
       "      <td>0.005741</td>\n",
       "      <td>0.028762</td>\n",
       "      <td>-0.000574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3021</th>\n",
       "      <td>1354878458753654787</td>\n",
       "      <td>0CBD8A826C40736F565B0332CD3FD3EB</td>\n",
       "      <td>1354848253729234944</td>\n",
       "      <td>MISINFORMED_OR_POTENTIALLY_MISLEADING</td>\n",
       "      <td>0.006203</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.213058</td>\n",
       "      <td>-0.006203</td>\n",
       "      <td>0.005741</td>\n",
       "      <td>-0.002123</td>\n",
       "      <td>-0.000574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2039</th>\n",
       "      <td>1354874966781657090</td>\n",
       "      <td>833DB7A8DD53BB58009275B560A225CA</td>\n",
       "      <td>1354848253729234944</td>\n",
       "      <td>MISINFORMED_OR_POTENTIALLY_MISLEADING</td>\n",
       "      <td>0.008363</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.073340</td>\n",
       "      <td>-0.008363</td>\n",
       "      <td>0.005741</td>\n",
       "      <td>0.018330</td>\n",
       "      <td>-0.000574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3152</th>\n",
       "      <td>1354863653435002881</td>\n",
       "      <td>A94B6B47281314FC0709C607970487B2</td>\n",
       "      <td>1354848253729234944</td>\n",
       "      <td>MISINFORMED_OR_POTENTIALLY_MISLEADING</td>\n",
       "      <td>0.011945</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.136535</td>\n",
       "      <td>-0.011945</td>\n",
       "      <td>0.005741</td>\n",
       "      <td>0.022755</td>\n",
       "      <td>-0.000574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   noteId                     participantId  \\\n",
       "894   1354875505246351360  7DCE02372757684773156C51BD8A856B   \n",
       "4657  1354862350009069568  52E7E8AC27398A29A5D8B54CD24439F9   \n",
       "1609  1354893429977849861  8F404408FB172B6104E0D8003C9B129C   \n",
       "4870  1354855483631423493  0CC2FBF56892C9911DFAFBA2C4FF2E4C   \n",
       "1431  1357798998405447682  02C657744DA50BCE2A90C2D4AB0CDC6E   \n",
       "981   1354875060885090309  DD591AE4F8045D93FFE2C45C394AC8DE   \n",
       "1590  1354868783840595969  9EE481CF8EDD9F2F08B20C7ED2C3355D   \n",
       "3021  1354878458753654787  0CBD8A826C40736F565B0332CD3FD3EB   \n",
       "2039  1354874966781657090  833DB7A8DD53BB58009275B560A225CA   \n",
       "3152  1354863653435002881  A94B6B47281314FC0709C607970487B2   \n",
       "\n",
       "                  tweetId                         classification  goodness  \\\n",
       "894   1354848253729234944  MISINFORMED_OR_POTENTIALLY_MISLEADING  0.005638   \n",
       "4657  1354848253729234944  MISINFORMED_OR_POTENTIALLY_MISLEADING  0.015433   \n",
       "1609  1354848253729234944  MISINFORMED_OR_POTENTIALLY_MISLEADING  0.021244   \n",
       "4870  1354848253729234944  MISINFORMED_OR_POTENTIALLY_MISLEADING  0.008414   \n",
       "1431  1354848253729234944  MISINFORMED_OR_POTENTIALLY_MISLEADING  0.017171   \n",
       "981   1354848253729234944  MISINFORMED_OR_POTENTIALLY_MISLEADING  0.015138   \n",
       "1590  1354848253729234944  MISINFORMED_OR_POTENTIALLY_MISLEADING  0.016435   \n",
       "3021  1354848253729234944  MISINFORMED_OR_POTENTIALLY_MISLEADING  0.006203   \n",
       "2039  1354848253729234944  MISINFORMED_OR_POTENTIALLY_MISLEADING  0.008363   \n",
       "3152  1354848253729234944  MISINFORMED_OR_POTENTIALLY_MISLEADING  0.011945   \n",
       "\n",
       "      verdict  writing_fairness  weighted_goodness  tweet_accuracy  \\\n",
       "894        -1          0.204779          -0.005638        0.005741   \n",
       "4657       -1          0.275441          -0.015433        0.005741   \n",
       "1609       -1          0.353497          -0.021244        0.005741   \n",
       "4870       -1          0.047435          -0.008414        0.005741   \n",
       "1431       -1          0.143030          -0.017171        0.005741   \n",
       "981        -1          0.205696          -0.015138        0.005741   \n",
       "1590       -1          0.211177          -0.016435        0.005741   \n",
       "3021       -1          0.213058          -0.006203        0.005741   \n",
       "2039       -1          0.073340          -0.008363        0.005741   \n",
       "3152       -1          0.136535          -0.011945        0.005741   \n",
       "\n",
       "      goodness_term1  goodness_term3  \n",
       "894        -0.002989       -0.000574  \n",
       "4657        0.019330       -0.000574  \n",
       "1609        0.028956       -0.000574  \n",
       "4870        0.021074       -0.000574  \n",
       "1431        0.037783       -0.000574  \n",
       "981         0.025419       -0.000574  \n",
       "1590        0.028762       -0.000574  \n",
       "3021       -0.002123       -0.000574  \n",
       "2039        0.018330       -0.000574  \n",
       "3152        0.022755       -0.000574  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notes.sort_values(by=['tweet_accuracy'],ascending=True).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "top = list(notes.sort_values(by=['tweet_accuracy'],ascending=False)[:100]['tweetId'])\n",
    "bottom = list(notes.sort_values(by=['tweet_accuracy'],ascending=True)[:666]['tweetId'])\n",
    "selected = set(top + bottom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_top = list(notes.sort_values(by=['tweet_accuracy'],ascending=False)[100:250]['tweetId'])\n",
    "next_bottom = list(notes.sort_values(by=['tweet_accuracy'],ascending=True)[666:1145]['tweetId'])\n",
    "next_selected = set(next_top+next_bottom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "top_ordered = list(OrderedDict.fromkeys(top))\n",
    "bottom_ordered = list(OrderedDict.fromkeys(bottom))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "next_top_ordered = list(OrderedDict.fromkeys(next_top))\n",
    "next_bottom_ordered = list(OrderedDict.fromkeys(next_bottom))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annotation Instruction and explanations : \n",
    "    \n",
    "#### Description of columns :\n",
    "\n",
    "tweet_favorite_count : Indicates approximately how many times this Tweet has been liked by Twitter users..\n",
    "\n",
    "tweet_possibly_sensitive : An indicator that the URL contained in the Tweet may contain content or media identified as sensitive content.\n",
    "\n",
    "tweet_retweet_count : Number of times this Tweet has been retweeted.\n",
    "\n",
    "tweet_text : The actual UTF-8 text of the status update. \n",
    "\n",
    "tweet_url : URL of the tweet.\n",
    "\n",
    "tweet_user_description : The bio of the twitter user.\n",
    "\n",
    "tweet_user_followers_count : The number of followers this account currently has.\n",
    "\n",
    "tweet_user_name : The name of the user, as they’ve defined it..\n",
    "\n",
    "tweet_user_protected : Indicates that this user has chosen to protect their Tweets\n",
    "\n",
    "tweet_user_screen_name : The screen name, handle, or alias that this user identifies themselves with.\n",
    "\n",
    "tweet_user_verified : Indicates that the user has a verified account.\n",
    "\n",
    "tweet_user_withheld_in_countries : When present, indicates a list of uppercase two-letter country codes this content is withheld from.\n",
    "\n",
    "#### What could each of these features say about the tweet being misleading/spreading misinformation/not being accurate?\n",
    "\n",
    "tweet_favorite_count and tweet_retweet_count: A misleading tweet from a visibly non reliable source could have lesser likes/retweets. But at the same time a misleading tweet from a popular account can have many likes/retweets. Similarly, very accurate tweets can have a high number of likes/retweets.  \n",
    "\n",
    "tweet_possibly_sensitive : At times tweets spreading misinfo can have sensitive media content. \n",
    "\n",
    "tweet_user_followers_count : Does a popular account that spreads misinfo have a lot of followers? DO fact checking websites have a lot of followers?\n",
    "\n",
    "tweet_user_name, tweet_user_screen_name or tweet_user_verified: The identity of the user (the name and the handle) and the verification status of the user can sometimes be enough to infer if the account could be a habitual/potential misinformation spreader or not. eg. The CDC account might not spread misinfo, but a bot account might be!\n",
    "\n",
    "tweet_user_protected : A user might protect thier tweets for variosu reasons. Perhaps, they had previously shared misinfo and are afraid of being reported? Perhaps, it could just be out of privacy concerns.\n",
    "\n",
    "tweet_user_withheld_in_countries : If the user's tweets are withheld in some countries, what could the reasons be? Is the user a habitual offender when it comes to hate speech, misinformation or abusive content? Or perhaps the user is whistleblower/journalist/activist, whose voice the said country wants to suppress?\n",
    "\n",
    "Instructions to annotate:\n",
    "\n",
    "For each of the tweets, consider as many features as you think are necessary to infer, subjectively, if the tweet is accurate or potentially misleading. Sometimes, it could be just easier to go to the URL of the tweet, assess the tweet on the Twitter website and make a decision. \n",
    "\n",
    "##### Once, you’ve made the decision, in the column ‘HUMAN ANNOTATION’,  add a ‘1’ if you think the tweet is ‘accurate’ or non-misleading. Else, add ‘0’.\n",
    "\n",
    "Special Cases :\n",
    "\n",
    "a.\tIf the URL field is empty or missing, you can go to the URL by using the following string : https://twitter.com/i/web/status/tweet_id, where tweet_id is the unique ID of the Tweet.\n",
    "\n",
    "b.\tIf all of the fields of the Tweet are missing, it was probably deleted. So you can annotate it with ‘0’\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We collect the above information for all tweets make a CSV file. _'tweet_groudtruth_annonation.csv'_ denotes the first set of tweets to be annotated (200 tweets) and _'tweet_groudtruth_annonation_next.csv'_ denotes the next set of the tweets (300 tweets) to be annotated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweet_info(api,tweet_id):\n",
    "    \n",
    "    tweet = api.get_status(tweet_id)\n",
    "    tweet_info = {}\n",
    "    tweet_info['tweet_id'] = str(tweet_id)+'id'\n",
    "    tweet_info['tweet_text'] = tweet.text\n",
    "    tweet_info['tweet_user_name'] = tweet.user.name\n",
    "    tweet_info['tweet_user_description'] = tweet.user.description\n",
    "    tweet_info['tweet_user_screen_name'] = tweet.user.screen_name\n",
    "    tweet_info['tweet_user_verified'] = tweet.user.verified\n",
    "    tweet_info['tweet_user_followers_count'] = tweet.user.followers_count\n",
    "    tweet_info['tweet_user_withheld_in_countries'] = tweet.user.withheld_in_countries\n",
    "    tweet_info['tweet_user_protected'] = tweet.user.protected\n",
    "    try: \n",
    "        tweet_info['tweet_url'] = tweet.entities['urls'][0]['expanded_url']\n",
    "    except IndexError as e:\n",
    "        tweet_info['tweet_url'] = None   \n",
    "    tweet_info['tweet_retweet_count'] = tweet.retweet_count\n",
    "    tweet_info['tweet_favorite_count'] = tweet.favorite_count\n",
    "    try: \n",
    "        tweet_info['tweet_possibly_sensitive'] = tweet.possibly_sensitive\n",
    "    except AttributeError as e:\n",
    "        tweet_info['tweet_possibly_sensitive'] = None   \n",
    "    return tweet_info\n",
    "\n",
    "def set_tweet_info_as_null(tweet_id):\n",
    "    \n",
    "    tweet_info = {}\n",
    "    tweet_info['tweet_id'] = str(tweet_id)+'id'\n",
    "    tweet_info['tweet_text'] = None\n",
    "    tweet_info['tweet_user_name'] = None\n",
    "    tweet_info['tweet_user_description'] = None\n",
    "    tweet_info['tweet_user_screen_name'] = None\n",
    "    tweet_info['tweet_user_verified'] = None\n",
    "    tweet_info['tweet_user_followers_count'] = None\n",
    "    tweet_info['tweet_user_withheld_in_countries'] = None\n",
    "    tweet_info['tweet_user_protected'] = None\n",
    "    tweet_info['tweet_url'] = None\n",
    "    tweet_info['tweet_retweet_count'] = None\n",
    "    tweet_info['tweet_favorite_count'] = None\n",
    "    tweet_info['tweet_possibly_sensitive'] = None\n",
    "    return tweet_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONSUMER_KEY = 'rZlo0NXfEvgpGuSIxT2v6AsBl'\n",
    "CONSUMER_SECRET = 'jnqdTr8y4LpYnor8l22y1gqOS6Z7y1mkMbsvXuuxG8wbJuYOAR'\n",
    "OAUTH_TOKEN = '583637312-v4WkMLaGqkwYUKKLQsrocp8tarCOM6XP7n4VMxuI'\n",
    "OAUTH_TOKEN_SECRET = 'c2KoPv7DCRF07aBWTRPUdexWHKioiYrpQfu47aRyppnjp'\n",
    "\n",
    "auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "auth.set_access_token(OAUTH_TOKEN, OAUTH_TOKEN_SECRET)\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "all_tweets_info = []\n",
    "for tweet_id in selected:\n",
    "    try:\n",
    "        tweet_info = get_tweet_info(api,tweet_id)\n",
    "    except tweepy.TweepError as e:\n",
    "        if e.args[0][0]['code'] == 144:\n",
    "            print(tweet_id)\n",
    "            tweet_info = set_tweet_info_as_null(tweet_id)\n",
    "    all_tweets_info.append(tweet_info)\n",
    "    \n",
    "tweet_info_df = pd.DataFrame(all_tweets_info,columns=['tweet_id','tweet_text','tweet_user_name','tweet_user_description','tweet_user_screen_name','tweet_user_verified','tweet_user_followers_count','tweet_user_verified','tweet_user_withheld_in_countries','tweet_user_protected','tweet_url','tweet_retweet_count','tweet_favorite_count','tweet_possibly_sensitive'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_info_df.to_csv('tweet_groudtruth_annonation.csv',encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONSUMER_KEY = 'rZlo0NXfEvgpGuSIxT2v6AsBl'\n",
    "CONSUMER_SECRET = 'jnqdTr8y4LpYnor8l22y1gqOS6Z7y1mkMbsvXuuxG8wbJuYOAR'\n",
    "OAUTH_TOKEN = '583637312-v4WkMLaGqkwYUKKLQsrocp8tarCOM6XP7n4VMxuI'\n",
    "OAUTH_TOKEN_SECRET = 'c2KoPv7DCRF07aBWTRPUdexWHKioiYrpQfu47aRyppnjp'\n",
    "\n",
    "auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "auth.set_access_token(OAUTH_TOKEN, OAUTH_TOKEN_SECRET)\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "all_tweets_info = []\n",
    "for tweet_id in next_selected:\n",
    "    try:\n",
    "        tweet_info = get_tweet_info(api,tweet_id)\n",
    "    except tweepy.TweepError as e:\n",
    "        if e.args[0][0]['code'] == 144:\n",
    "            print(tweet_id)\n",
    "            tweet_info = set_tweet_info_as_null(tweet_id)\n",
    "    all_tweets_info.append(tweet_info)\n",
    "    \n",
    "tweet_info_df_next = pd.DataFrame(all_tweets_info,columns=['tweet_id','tweet_text','tweet_user_name','tweet_user_description','tweet_user_screen_name','tweet_user_verified','tweet_user_followers_count','tweet_user_verified','tweet_user_withheld_in_countries','tweet_user_protected','tweet_url','tweet_retweet_count','tweet_favorite_count','tweet_possibly_sensitive'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_info_df_next_shuffled = tweet_info_df_next.sample(frac=1)\n",
    "tweet_info_df_next_shuffled.to_csv('tweet_groudtruth_annonation_next.csv',encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### At this point, the annotators annotate the sheets. We  put 0 for no unanimous decision by annotators. After the annotation is done we read the CSV again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_annotation_df_next = pd.read_csv('tweet_groudtruth_annonation_next.csv',encoding='utf-8-sig')\n",
    "tweet_annotation_df = pd.read_csv('tweet_groudtruth_annonation.csv',encoding='utf-8-sig')\n",
    "tweet_annotation = pd.concat([tweet_annotation_df, tweet_annotation_df_next])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We  employ  a  unsupervised method to detect misinformation tweets for theHawkEye system. For each tweet, from the notes written for the tweet, we select notes having a credibility of at least 0.02. Among these  notes,  if  the  number  of  notes  that  labeled  the  tweet  as misleading are more than or equal to the number of notes thatlabeled  the  tweet  as  not  misleading,  HawkEye  classifies  the tweet as misleading. We compare these Hawkeye derived labels with our annotators labels and report the accruacy, precision and recall. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.94      0.64       124\n",
      "           1       0.97      0.68      0.80       376\n",
      "\n",
      "    accuracy                           0.74       500\n",
      "   macro avg       0.73      0.81      0.72       500\n",
      "weighted avg       0.85      0.74      0.76       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "y_true,y_pred = [],[]\n",
    "for idx,row in tweet_annotation.iterrows():\n",
    "    \n",
    "    y_true.append(row['human_annotation'])\n",
    "    notesForTweet = notes.loc[notes['tweetId'] == int(row['tweet_id'][:-2])]\n",
    "    notesForTweetCredible = notesForTweet[notesForTweet['goodness'] >= 0.02]\n",
    "    \n",
    "    scoredNotes_misleading = notesForTweetCredible.loc[notesForTweetCredible['classification'] == 'MISINFORMED_OR_POTENTIALLY_MISLEADING']\n",
    "    scoredNotes_notmisleading = notesForTweetCredible.loc[notesForTweetCredible['classification'] == 'NOT_MISLEADING']\n",
    "#     print(\"scoredNotes_misleading = \",scoredNotes_misleading)\n",
    "#     print(\"scoredNotes_notmisleading = \",scoredNotes_notmisleading)\n",
    "#     break\n",
    "    if len(scoredNotes_misleading) >= len(scoredNotes_notmisleading): # >= scoredNotesNotMisleading['helpful'].sum():\n",
    "        y_pred.append(0)\n",
    "    else:\n",
    "        y_pred.append(1)\n",
    "\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We confirm the annotator agreement. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.005681407323895105\n"
     ]
    }
   ],
   "source": [
    "import statsmodels\n",
    "from statsmodels.stats.inter_rater import fleiss_kappa\n",
    "\n",
    "annotations_array = np.array(tweet_annotation[['annotation_rohit','annotation_mohit','annotation_soyoung']])\n",
    "#fleiss_kappa(annotations_array)\n",
    "import krippendorff\n",
    "kappa = krippendorff.alpha(annotations_array)\n",
    "print(kappa)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
